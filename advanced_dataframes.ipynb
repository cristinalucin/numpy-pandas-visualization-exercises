{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92760c",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Run python -m pip install pymysql from your terminal to install the mysql client (any folder is fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named get_db_url. It should accept a username, hostname, password, and database name \n",
    "#  and return a url connection string \n",
    "# formatted like in the example at the start of this lesson.\n",
    "#from env import host, user, password\n",
    "def get_db_url(db):\n",
    "    from env import host, user, password\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2e2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 3 Use your function to obtain a connection to the employees database.\n",
    "\n",
    "pd.read_sql('SELECT * FROM employees LIMIT 5 OFFSET 50', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3257b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    *\n",
    "FROM employees\n",
    "'''\n",
    "employees_df = pd.read_sql(sql, url)\n",
    "employees_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 How many rows and columns do you have in each DataFrame? Is that what you expected?\n",
    "employees_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    *\n",
    "FROM titles\n",
    "'''\n",
    "titles_df = pd.read_sql(sql, url)\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Display the summary statistics for each DataFrame.\n",
    "print(titles_df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d32691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 How many unique titles are in the titles DataFrame?\n",
    "titles_df.title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 What is the oldest date in the to_date column?\n",
    "#titles_df.sort_values(by='to_date' == )\n",
    "titles_df[titles_df.to_date == titles_df.to_date.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 What is the most recent date in the to_date column?\n",
    "#titles_df[titles_df.to_date == titles_df.to_date.max()]\n",
    "titles_df.sort_values(by=['to_date'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a23cde",
   "metadata": {},
   "source": [
    "## Exercises II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the users and roles DataFrames from the examples above.\n",
    "# 1 Create the users DataFrame.\n",
    "\n",
    "users = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5, 6],\n",
    "    'name': ['bob', 'joe', 'sally', 'adam', 'jane', 'mike'],\n",
    "    'role_id': [1, 2, 3, 3, np.nan, np.nan]\n",
    "})\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the roles DataFrame\n",
    "\n",
    "roles = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'name': ['admin', 'author', 'reviewer', 'commenter']\n",
    "})\n",
    "roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 What is the result of using a right join on the DataFrames?\n",
    "# Perform an outer join specifying the left and right DataFrame keys.\n",
    "\n",
    "users.merge(roles, left_on='role_id', right_on='id', how='right', indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd550195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 What is the result of using an outer join on the DataFrames?\n",
    "users.merge(roles, left_on='role_id', right_on='id', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bc8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 What happens if you drop the foreign keys from the DataFrames and try to merge them?\n",
    "\n",
    "pd.merge(users, roles,\n",
    "        how='outer',\n",
    "        indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Load the mpg dataset from PyDataset.\n",
    "mpg = data('mpg') # load the dataset and store it in a variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Output and read the documentation for the mpg dataset.\n",
    "data('mpg', show_doc=True) # view the documentation for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640db321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 How many rows and columns are in the dataset?\n",
    "mpg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Check out your column names and perform any cleanup you may want on them.\n",
    "mpg.rename(columns={'cty': 'city'}, inplace = True)\n",
    "mpg.rename(columns={'hwy': 'highway'}, inplace = True)\n",
    "mpg.rename(columns={'cyl': 'cylinder'}, inplace = True)\n",
    "mpg.rename(columns={'trans': 'transmission'}, inplace = True)\n",
    "mpg.rename(columns={'displ': 'displacement'}, inplace = True)\n",
    "mpg.rename(columns={'drv': 'drive'}, inplace = True)\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5583cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Display the summary statistics for the dataset.\n",
    "print(mpg.describe()) \n",
    "print(mpg.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1538e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 How many different manufacturers are there?\n",
    "#mpg_makes = mpg[\"manufacturer\"].unique()\n",
    "make_unique = mpg['manufacturer'].nunique() \n",
    "#or\n",
    "mpg.manufacturer.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 How many different models are there?\n",
    "model_unique = mpg['model'].nunique() \n",
    "#or\n",
    "mpg.model.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 Create a column named mileage_difference like you did in the DataFrames exercises; \n",
    "# this column should contain the difference between highway and city mileage for each car.\n",
    "\n",
    "mpg = mpg.assign(mileage_difference = (mpg['highway']-mpg['city'])) \n",
    "#or\n",
    "mpg ['mileage_difference'] = mpg.highway - mpg.city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 Create a column named average_mileage like you did in the DataFrames exercises; this is the \n",
    "# mean of the city and highway mileage.\n",
    "# Create a column named average_mileage that is the mean of the city and highway mileage.\n",
    "mpg[\"average_mileage\"] = (mpg.highway + mpg.city) /2\n",
    "#or\n",
    "mpg = mpg.assign(average_mileage = (mpg['highway'] + mpg['city']) / 2) \n",
    "#try this harmonic mean\n",
    "mpg['average_mileage'] = round (2/ ((1/mpg.highway) + (1/mpg.city)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 Create a new column on the mpg dataset named is_automatic that holds boolean values denoting \n",
    "# whether the car has an automatic transmission.\n",
    "mpg.transmission.unique()\n",
    "mpg[\"is_automatic\"] = mpg[\"transmission\"].str.contains(\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 Using the mpg dataset, find out which which manufacturer has the best miles per gallon on average?\n",
    "mpg.groupby(\"manufacturer\").average_mileage.mean().nlargest()\n",
    "# Honda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d50f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#16 Do automatic or manual cars have better miles per gallon?\n",
    "# Choose only two columns for my subset.\n",
    "\n",
    "mpg['transmission_catgeory'] = np.where (mpg.transmission.str.contains('auto'),'automatic', 'manual')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e07a2",
   "metadata": {},
   "source": [
    "## Exercises Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Use your get_db_url function to help you explore the data from the chipotle database.\n",
    "def get_db_url():\n",
    "    from env import host, user, password\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/chipotle'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b306a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orders_df = pd.read_sql('SELECT * FROM orders', url)\n",
    "orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94678f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 What is the total price for each order?\n",
    "#change datatype of column, clean columns\n",
    "#orders_df['item_price'] = orders_df['item_price'].str.replace('$', '')\n",
    "#orders_df['item_price'] = orders_df['item_price'].astype(float)\n",
    "order_totals = orders_df.groupby('order_id').item_price.sum()\n",
    "#or orders_df['item_price'] = orders_df['item_price'].str.replace('$', '').astype[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 What are the most popular 3 items?\n",
    "orders_df.groupby('item_name').quantity.sum().sort_values(ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Which item has produced the most revenue?\n",
    "item_revenue = orders_df.groupby('item_name').item_price.sum()\n",
    "item_revenue.nlargest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Join the employees and titles DataFrames together.\n",
    "\n",
    "from env import host, user, password\n",
    "url = f'mysql+pymysql://{user}:{password}@{host}/employees'\n",
    "    \n",
    "def get_db_url():\n",
    "    from env import host, user, password\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/employees'\n",
    "    return url\n",
    "\n",
    "sql = '''\n",
    "SELECT\n",
    "    *\n",
    "FROM employees\n",
    "'''\n",
    "employees = pd.read_sql(sql, url)\n",
    "employees.head()\n",
    "\n",
    "sql = '''\n",
    "SELECT\n",
    "    *\n",
    "FROM titles\n",
    "'''\n",
    "titles = pd.read_sql(sql, url)\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import host, user, password\n",
    "url = f'mysql+pymysql://{user}:{password}@{host}/employees'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbe97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Join the employees and titles DataFrames together.\n",
    "# Perform an outer join specifying the left and right DataFrame keys.\n",
    "\n",
    "#employees.merge(titles, left_on='emp_no', right_on='emp_no', how='inner', indicator=True)\n",
    "merged_df = employees.merge(titles, left_on='emp_no', right_on='emp_no', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_url():\n",
    "    from env import host, user, password\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/employees'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 For each title, find the hire date of the employee that was hired most recently with that title.\n",
    "merged_df.groupby(\"title\").hire_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Write the code necessary to create a cross tabulation of the number of titles by department. \n",
    "# (Hint: this will involve a combination of SQL code to pull the necessary data and python/pandas \n",
    "# code to perform the manipulations.)\n",
    "\n",
    "#sql = '''\n",
    "#SELECT\n",
    "#    *\n",
    "#FROM departments\n",
    "#'''\n",
    "#departments = pd.read_sql(sql, url)\n",
    "#departments.head()\n",
    "dept_title_query = '''\n",
    "                    SELECT t.emp_no,\n",
    "                    t.title,\n",
    "                    t.to_date,\n",
    "                    d.dept_name\n",
    "                    FROM departments AS d\n",
    "                    JOIN dept_emp AS de USING(dept_no)\n",
    "                    JOIN titles as t USING(emp_no)\n",
    "\n",
    "'''\n",
    "dept_titles = pd.read_sql(dept_title_query, get_db_url('employees'))\n",
    "dept_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_db_url('employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae1895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
